{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7738a294",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b24fe9c",
   "metadata": {},
   "source": [
    "Safran Electronics & Defense is developing a multi-target detection, classification, tracking and localization video chain for land, sea and airborne defence applications to assist operators in their missions.\n",
    "\n",
    "This video chain can be deployed in the context of directional sights, handheld cameras, panoramic surveillance sights, or distributed wide field sensors. \n",
    "\n",
    "Safran Electronics & Defense wishes to optimize the valorization of its image & video database, which is heterogeneous, both in terms of content (type of campaign air, land, sea, type of sensor, associated metadata of navigation, image content, etc etc) and in terms of form (file format). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d04906d",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8405f15",
   "metadata": {},
   "source": [
    "As part of our annual INFONUM project, we are partnering with the company SAFRAN.\n",
    " \n",
    "Thus, within the framework of this project, we have to set up an architecture for extracting metadata each time a new file is added to the storage server. This architecture includes different bricks (extraction module, database, GUI, etc.) and notably AI bricks. Our partner gave us the freedom to choose what we would like to implement and we chose to work on a Deep Learning module allowing us to classify the contexts to which the imported images could belong (aerial, rural, maritime, desert, mountainous context).\n",
    " \n",
    "Having seen that it was possible to couple the project of the Deep Learning module with the project of another course requiring a Deep Learning part, we thus made the choice to link these two projects.\n",
    " \n",
    "The team is composed of two students: LEVY Daniel and PUJOL Corentin. As I stated above, we want to implement and compare different Deep Learning approaches to extract the context of different images. The objective would be to implement different models (ResNet, MobileNet, VGG for example) and to study their hyperparameters in order to obtain the best possible results on context extraction. The data used will be those proposed by the partner. As the partner has not yet provided us with the data, we have found several sources allowing us to start working with a dataset obtained from the Kaggle platform. \n",
    " \n",
    "The approach we would like to take would be to implement different pre-trained models, then to perform Transfer Learning (with and without fine-tuning) in order to make these models perform well on our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4f8b6e",
   "metadata": {},
   "source": [
    "## Dataset presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302ecca5",
   "metadata": {},
   "source": [
    "This is Landscape classification dataset. This data consists of 5 different classes. Each class representing a kind of landscape. These classes are :\n",
    "\n",
    "    Coast\n",
    "    This class contains images belonging to coastal areas, or simply beaches.\n",
    "\n",
    "    Desert\n",
    "    This class contains images of desert areas such as Sahara Thar, etc.\n",
    "\n",
    "    Forest\n",
    "    This class is filled with images belonging to forest areas such as Amazon.\n",
    "\n",
    "    Glacier\n",
    "    This class consists of some amazing white images, These images belongs to glaciers. For example, the Antarctic.\n",
    "\n",
    "    Mountains\n",
    "    This class shows you the world from the top i.e. the mountain areas such as the Himalayas.\n",
    "    \n",
    "This data is first divided into 3 sub directories. These sub directories are the training, validation, and testing data directories. Another directory of tensorflow records is also added, which is further divided into 3 directories of training, validation and testing data, containing the tensorflow records of these images. This allow you to load the data both using Image Data Generator, or using the tensorflow records.\n",
    "\n",
    "From my perspective for any. For any model to perform well on this data set, the model should have proper knowledge of the colors and the geometry of the image. Because when both the colors and geometry come together, they make up a landscape."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69185df",
   "metadata": {},
   "source": [
    "## Our approach to the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da14960",
   "metadata": {},
   "source": [
    "In order to succeed in determining the best performing model, we will load the infrastructures of four well-known models, already performing well on more global data sets. The objective is to re-train these models on the data of our problem.\n",
    "\n",
    "We will divide the training phase into several steps in order to study each hyperparameter, understand how they work and finally choose the ones that will make the models perform best with respect to our initial problem.\n",
    "\n",
    "After loading the pre-trained architectures, in order to avoid any fine-tuning of the first layers of the network, the gradients of the corresponding parameters must be frozen. Then, in order to perform the learning transfer, we will replace the last classification layer by the one appropriate to our problem. Thus, our prediction layer will be trained on our new data based on the performance of the previous layers already pre-trained. Once this step is completed, we will proceed to a fine-tuning step, in order to adjust the parameters of all the layers of our models.\n",
    "\n",
    "To do so, we will define the cost function adapted to the problem and we will first apply the gradient descent\n",
    "to the parameters of the newly defined fully connected layer only, with the different hyperparameters chosen. We will compare the performance of the model according to the chosen hyperparameters in order to determine which ones are the most suitable for training our models.\n",
    "\n",
    "After training the new fully connected layer, we will untrain the upper layers of the model in the fine-tuning stage. We will follow the same approach as in the transfer learning step in order to make our models as efficient as possible.\n",
    "\n",
    "We assume that some hyperparameters do not have the same effect depending on the architecture they are applied to, so we expect to get very good results on the different models but with different chosen hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fd39b0",
   "metadata": {},
   "source": [
    "### Selected pre-trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1329120c",
   "metadata": {},
   "source": [
    "Resnet18, MobileNet, AlexNet, VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f4994e",
   "metadata": {},
   "source": [
    "### Hyperparameters studied"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ad998f",
   "metadata": {},
   "source": [
    "Hyperparameters are adjustable parameters that let you control the model optimization process. Different hyperparameter values can impact model training and convergence rates (read more about hyperparameter tuning)\n",
    "\n",
    "We define the following hyperparameters for training:\n",
    "\n",
    "- Number of Epochs - the number times to iterate over the dataset\n",
    "\n",
    "    Use of early stopping to record only the best and not the last model (recording only when the loss decreases)\n",
    "\n",
    "- Batch Size - the number of data samples propagated through the network before the parameters are updated\n",
    "\n",
    "    Try [16, 32, 64, 128, 256] but in fact, smallers should be better according some research (https://reader.elsevier.com/reader/sd/pii/S2405959519303455?token=C37354B4B0DEA9791B9005F04612342318223AC16CAF73061D563AC0CF8937F435433C40BB033FEBDFA6AF09F4C5A4FB&originRegion=eu-west-1&originCreation=20230216143607)\n",
    "    \n",
    "- Learning Rate - how much to update models parameters at each batch/epoch. Smaller values yield slow learning speed, while large values may result in unpredictable behavior during training.\n",
    "\n",
    "    How to adjust learning rate\n",
    "\n",
    "    torch.optim.lr_scheduler provides several methods to adjust the learning rate based on the number of epochs. torch.optim.lr_scheduler.ReduceLROnPlateau allows dynamic learning rate reducing based on some validation measurements.\n",
    "\n",
    "    Learning rate scheduling should be applied after optimizerâ€™s update; e.g., you should write your code this way:\n",
    "\n",
    "    Example:\n",
    "\n",
    "        model = [Parameter(torch.randn(2, 2, requires_grad=True))]\n",
    "\n",
    "        optimizer = SGD(model, 0.1)\n",
    "\n",
    "        scheduler = ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "        for epoch in range(20):\n",
    "\n",
    "            for input, target in dataset:\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                output = model(input)\n",
    "                loss = loss_fn(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f081c022",
   "metadata": {},
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3af4f0b",
   "metadata": {},
   "source": [
    "We have to choose a loss function to make all our experiences.\n",
    "\n",
    "Then, explain why ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb26534",
   "metadata": {},
   "source": [
    "### Optimizer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f2594e",
   "metadata": {},
   "source": [
    "Optimization is the process of adjusting model parameters to reduce model error in each training step. Optimization algorithms define how this process is performed.  All optimization logic is encapsulated in the optimizer object. Here, we use the SGD optimizer; additionally, there are many different optimizers available in PyTorch such as ADAM and RMSProp, that work better for different kinds of models and data.\n",
    "\n",
    "We initialize the optimizer by registering the modelâ€™s parameters that need to be trained, and passing in the learning rate hyperparameter.\n",
    "\n",
    "Example with SGD algorithm: \n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "Link to see all the existing algorithms (SGD, Adagrad, RMSProp, Adam, NAdam, etc...) : https://pytorch.org/docs/stable/optim.html\n",
    "\n",
    "The different optimizers can be divided in two families: gradient descent optimizers and adaptive optimizers. This division is exclusively based on an operational aspect which forces you to manually tune the learning rate in the case of Gradient Descent algorithms while it is automatically adapted in adaptive algorithms â€” thatâ€™s why we have this name.\n",
    "\n",
    "    Gradient Descent:\n",
    "\n",
    "    Batch gradient descent\n",
    "    Stochastic gradient descent\n",
    "    Mini-batch gradient descent\n",
    "    \n",
    "    Adaptive:\n",
    "\n",
    "    Adagrad\n",
    "    RMSprop\n",
    "    Adam \n",
    "    \n",
    "https://towardsdatascience.com/7-tips-to-choose-the-best-optimizer-47bb9c1219e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5aa2c6",
   "metadata": {},
   "source": [
    "### Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca9d123",
   "metadata": {},
   "source": [
    "Regularization techniques are used to prevent overfitting by adding a penalty to the model's loss function. Some common regularization techniques include weight decay (L2 regularization), dropout, and batch normalization.\n",
    "\n",
    "We can try also data augmention, if it can help us to reach better result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b73c7fb",
   "metadata": {},
   "source": [
    "### Bonus : Activation function  \n",
    "\n",
    "(Relu, softmax, sigmoÃ¯d, tanh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e8f06a",
   "metadata": {},
   "source": [
    "## Experiences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0eecee8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coco8\\anaconda3\\envs\\safranproject\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\coco8\\anaconda3\\envs\\safranproject\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from module import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40715344",
   "metadata": {},
   "source": [
    "Images normalization for pytorch pretrained models*\n",
    "\n",
    "voir: https://pytorch.org/docs/stable/torchvision/models.html et ici pour les Â« explications Â» sur les valeurs exactes: https://github.com/pytorch/vision/issues/1439"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a024f602",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize([224, 224]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean, std=std)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a0720f",
   "metadata": {},
   "source": [
    "We define the image directory for our personal data and the test_size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f62f512f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_directory = \"C:/Users/coco8/Documents/CentraleSupelec/Projet_annÃ©e_local/dataset\"\n",
    "test_size = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8eaa6b6",
   "metadata": {},
   "source": [
    "Here is the dataset function that we define in module.py. This function allow us to load correctly all our data from the directory to three variables : dataset_train, dataset_val, dataset_test. These variables allow us to handle easily our images and to give it to our different pretrained models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8eebc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, dataset_val, dataset_test = dataset(data_transforms, image_directory, test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c36bf200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available :  True\n",
      "__CUDNN VERSION: 8302\n",
      "__Number CUDA Devices: 1\n",
      "__CUDA Device Name: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "__CUDA Device Total Memory [GB]: 6.441926656\n"
     ]
    }
   ],
   "source": [
    "# on utilisera le GPU (beaucoup plus rapide) si disponible, sinon on utilisera le CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\") # forcer en CPU s'il y a des problÃ¨mes de mÃ©moire GPU (+ Ãªtre patient...)\n",
    "print(\"GPU available : \",torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "    print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "    print('__CUDA Device Name:',torch.cuda.get_device_name(0))\n",
    "    print('__CUDA Device Total Memory [GB]:',torch.cuda.get_device_properties(0).total_memory/1e9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c8d237",
   "metadata": {},
   "source": [
    "Loading of the pretrained models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bc2aa7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coco8\\anaconda3\\envs\\safranproject\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to C:\\Users\\coco8/.cache\\torch\\hub\\checkpoints\\mobilenet_v2-b0353104.pth\n",
      "100.0%\n",
      "C:\\Users\\coco8\\anaconda3\\envs\\safranproject\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to C:\\Users\\coco8/.cache\\torch\\hub\\checkpoints\\vgg16-397923af.pth\n",
      "62.7%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "85.8%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "resnet18 = models.resnet18(pretrained=True)\n",
    "mobilenet = models.mobilenet_v2(pretrained=True)\n",
    "vgg16 = models.vgg16(pretrained=True)\n",
    "alexnet = models.alexnet(pretrained=True)\n",
    "\n",
    "my_models = [resnet18, mobilenet, vgg16, alexnet]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee67e7b",
   "metadata": {},
   "source": [
    "Transfer learning with fine tunning:\n",
    "\n",
    "https://towardsdatascience.com/transfer-learning-with-convolutional-neural-networks-in-pytorch-dd09190245ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf9ba7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for my_net in my_models:  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
